{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Po6YNEbZRmOp"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pennylane as qml\n",
        "import pennylane.numpy as np\n",
        "from typing import List, Dict, Tuple\n",
        "import pandas as pd\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "import logging\n",
        "\n",
        "# Quantum Base-10 Controller Class\n",
        "class QuantumBase10Controller:\n",
        "    def __init__(self, num_qubits=4):\n",
        "        self.num_qubits = num_qubits\n",
        "        self.device = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "    def base10_model(self, alpha: float) -> np.ndarray:\n",
        "        x = alpha / 10\n",
        "\n",
        "        @qml.qnode(self.device)\n",
        "        def circuit():\n",
        "            # Base-10 state preparation with heaviside transitions\n",
        "            for i in range(self.num_qubits):\n",
        "                theta = np.pi * np.heaviside(np.sin(10 * (2**i) * np.pi * x + np.pi/4), 0.5)\n",
        "                qml.RY(theta, wires=i)\n",
        "\n",
        "            # Enhanced entanglement for base-10 encoding\n",
        "            for i in range(self.num_qubits - 1):\n",
        "                qml.CNOT(wires=[i, i+1])\n",
        "                qml.PhaseShift(np.pi/10, wires=i)\n",
        "\n",
        "            return qml.probs(wires=range(self.num_qubits))\n",
        "\n",
        "        # Execute the quantum node\n",
        "        return circuit()\n",
        "\n",
        "    def generate_base10_coefficients(self):\n",
        "        \"\"\"Generate coefficients for perfect base-10 state preparation\"\"\"\n",
        "        coefs = np.linspace(0, 10, 10, endpoint=False)\n",
        "        return [c + np.pi/40 for c in coefs]\n",
        "\n",
        "    def test_base10_states(self):\n",
        "        coefs = self.generate_base10_coefficients()\n",
        "        results = []\n",
        "\n",
        "        for alpha in coefs:\n",
        "            probs = self.base10_model(alpha)\n",
        "            state_index = np.argmax(probs)\n",
        "\n",
        "            results.append({\n",
        "                'alpha': alpha,\n",
        "                'state_index': state_index,\n",
        "                'probability': probs[state_index],\n",
        "                'probabilities': probs.tolist()\n",
        "            })\n",
        "\n",
        "            print(f\"Alpha: {alpha:.3f}, State: {state_index}, Probability: {probs[state_index]:.4f}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "# Main Analysis Class\n",
        "class QubitScalingAnalyzer:\n",
        "    def __init__(self, start_qubits=4, max_qubits=16, step=2):\n",
        "        self.start_qubits = start_qubits\n",
        "        self.max_qubits = max_qubits\n",
        "        self.step = step\n",
        "        self.results_dir = f\"scaling_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "        os.makedirs(self.results_dir, exist_ok=True)\n",
        "\n",
        "        # Set up logging\n",
        "        logging.basicConfig(\n",
        "            filename=f\"{self.results_dir}/analysis.log\",\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "\n",
        "    def analyze_state(self, probs: np.ndarray, num_qubits: int) -> Dict:\n",
        "        try:\n",
        "            state_index = np.argmax(probs)\n",
        "            state_binary = format(state_index, f'0{num_qubits}b')\n",
        "\n",
        "            # Safe entropy calculation\n",
        "            probs = np.array(probs)\n",
        "            valid_probs = probs[probs > 1e-10]\n",
        "            entropy = -np.sum(valid_probs * np.log2(valid_probs + 1e-10))\n",
        "\n",
        "            return {\n",
        "                'dominant_state': state_binary,\n",
        "                'max_probability': float(probs[state_index]),\n",
        "                'entropy': float(entropy),\n",
        "                'num_significant_states': int(np.sum(probs > 0.01)),\n",
        "                'hilbert_space_dimension': 2**num_qubits\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logging.error(f\"State analysis failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def run_single_qubit_test(self, num_qubits: int) -> Dict:\n",
        "        try:\n",
        "            controller = QuantumBase10Controller(num_qubits)\n",
        "\n",
        "            # Test points\n",
        "            alphas = controller.generate_base10_coefficients()\n",
        "            results = []\n",
        "\n",
        "            start_time = time.time()\n",
        "            start_memory = psutil.Process().memory_info().rss / 1024 / 1024\n",
        "\n",
        "            for alpha in alphas:\n",
        "                probs = controller.base10_model(alpha)\n",
        "                analysis = self.analyze_state(probs, num_qubits)\n",
        "                results.append(analysis)\n",
        "\n",
        "            end_time = time.time()\n",
        "            end_memory = psutil.Process().memory_info().rss / 1024 / 1024\n",
        "\n",
        "            return {\n",
        "                'num_qubits': num_qubits,\n",
        "                'execution_time': end_time - start_time,\n",
        "                'memory_usage_mb': end_memory - start_memory,\n",
        "                'avg_entropy': np.mean([r['entropy'] for r in results]),\n",
        "                'max_probability': max([r['max_probability'] for r in results]),\n",
        "                'avg_significant_states': np.mean([r['num_significant_states'] for r in results]),\n",
        "                'results': results\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Test failed for {num_qubits} qubits: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def run_analysis(self):\n",
        "        summary_data = []\n",
        "\n",
        "        for num_qubits in range(self.start_qubits, self.max_qubits + 1, self.step):\n",
        "            print(f\"\\nAnalyzing {num_qubits} qubits...\")\n",
        "            logging.info(f\"Starting analysis for {num_qubits} qubits\")\n",
        "\n",
        "            try:\n",
        "                result = self.run_single_qubit_test(num_qubits)\n",
        "                summary_data.append(result)\n",
        "\n",
        "                # Save detailed results\n",
        "                df = pd.DataFrame(result['results'])\n",
        "                df.to_csv(f\"{self.results_dir}/qubits_{num_qubits}_results.csv\", index=False)\n",
        "\n",
        "                logging.info(f\"Completed analysis for {num_qubits} qubits\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Failed at {num_qubits} qubits: {str(e)}\")\n",
        "                logging.error(f\"Analysis failed at {num_qubits} qubits: {str(e)}\")\n",
        "                break\n",
        "\n",
        "        self.generate_summary_report(summary_data)\n",
        "\n",
        "    def generate_summary_report(self, summary_data):\n",
        "        if not summary_data:\n",
        "            print(\"No data collected!\")\n",
        "            return\n",
        "\n",
        "        df = pd.DataFrame([{k:v for k,v in d.items() if k != 'results'} for d in summary_data])\n",
        "\n",
        "        # Save summary data\n",
        "        df.to_csv(f\"{self.results_dir}/scaling_summary.csv\", index=False)\n",
        "\n",
        "        analysis_text = [\n",
        "            \"=== Quantum System Scaling Analysis ===\\n\",\n",
        "            f\"Analysis completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
        "            f\"\\nSuccessfully tested qubit ranges: {df['num_qubits'].min()} to {df['num_qubits'].max()}\",\n",
        "            f\"\\nPerformance Metrics:\",\n",
        "            f\"- Average execution time per qubit: {df['execution_time'].mean():.2f} seconds\",\n",
        "            f\"- Average memory usage per qubit: {df['memory_usage_mb'].mean():.2f} MB\",\n",
        "            f\"\\nQuantum State Metrics:\",\n",
        "            f\"- Average entropy range: {df['avg_entropy'].min():.2f} to {df['avg_entropy'].max():.2f}\",\n",
        "            f\"- Maximum achieved probability: {df['max_probability'].max():.4f}\",\n",
        "            f\"\\nDetailed scaling analysis saved in: {self.results_dir}\"\n",
        "        ]\n",
        "\n",
        "        report = '\\n'.join(analysis_text)\n",
        "        print(report)\n",
        "\n",
        "        with open(f\"{self.results_dir}/scaling_analysis_report.txt\", 'w') as f:\n",
        "            f.write(report)\n",
        "            f.write(\"\\n\\nFull Data Summary:\\n\")\n",
        "            f.write(df.to_string())\n",
        "\n",
        "# Run the analysis\n",
        "def main():\n",
        "    analyzer = QubitScalingAnalyzer(start_qubits=4, max_qubits=16, step=2)\n",
        "    analyzer.run_analysis()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}